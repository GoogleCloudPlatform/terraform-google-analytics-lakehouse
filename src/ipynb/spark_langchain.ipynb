{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c79ba30-439d-4064-a2ac-859ea887ce75",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339cf14-d890-458e-9587-21a788936ab2",
   "metadata": {},
   "source": [
    "### Install Langchain\n",
    "\n",
    "Install the `langchain`, `langchain-experimental`, and `langchain-google-geni` libraries. You can install these directly into your Spark Serverless environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdf160-2885-43c3-86d3-cfb3f605eb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install langchain langchain-experimental langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dbf357-d8b3-4038-84d2-19b06b49bf9a",
   "metadata": {},
   "source": [
    "### Create an API key\n",
    "\n",
    "Create an API key using <a href=\"https://aistudio.google.com/app/apikey\"><span style=\"color:blue\">Google AI Studio</span></a>. Run the next cell and paste the API key in when prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1d896-164e-4c56-87d2-04447ee9d628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4709327-ca03-4b31-9a86-4df91c4dd788",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce553641-3093-4016-9e17-20a76e4e2aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_spark_dataframe_agent\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e2e70-f2ab-4394-9332-8d6499ea3bb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a connection to the Gemini model service\n",
    "\n",
    "Create an LLM object using the `GoogleGenerativeAI` class which creates a connection to the Gemini model service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d47140-434a-4a0a-96e1-d62b9192e519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.0, google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588bf4b5-e5f9-4437-923e-11430713cddf",
   "metadata": {},
   "source": [
    "Use `llm.invoke` to ask Gemini a question and confirm your connection to the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d713cb8-c656-4285-9050-b2b6a9d2c1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(llm.invoke(\"What is the best programming language?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b9819-2142-43fb-ab40-d1ff82d8bf8f",
   "metadata": {},
   "source": [
    "### Create a Spark Session\n",
    "\n",
    "Create a connection to the Spark context in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16d694-4652-4c38-98ec-88a24df5e175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d266c0-c32b-437e-a36a-79a339288c65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data\n",
    "\n",
    "Load your BigLake table `gcp_primary_staging.thelook_ecommerce_order_items` into your environment. This table contains ecommerce orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0288a55-d7c5-4843-b5bd-c510b82a549c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"bigquery\").load(\"next-2024-spark-demo.gcp_primary_staging.thelook_ecommerce_order_items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0f829-6506-4607-95cf-30882ce7bd15",
   "metadata": {
    "tags": []
   },
   "source": [
    "View some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c40cda-092e-4f8e-bd7e-2be47559e8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825a341-2230-4e85-b482-9b378979c13e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use the `create_spark_dataframe_agent` method to configure a LangChain agent using the loaded dataset and Gemini model. The `verbose=True` parameter, send to std.out the steps the agent is taking. Omitting this parameter to suppresses this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986ec6b-4dd8-4102-92b0-74479da4351b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_spark_dataframe_agent(llm=llm, df=df, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f7bd72-4082-40c9-adc6-1312490d8a1d",
   "metadata": {},
   "source": [
    "Use natural language to gain insights into your data. To start with something simple, ask for the order_id and the price of the most expensive order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc9524-5d36-46f6-b8cc-21c6849708cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.invoke(\"what was the order id and the price of the most expensive order?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172275f-51cb-4fdc-b803-a34c28aca7f8",
   "metadata": {},
   "source": [
    "With the verbose parameter set to True, we can see exactly how the agent is working. The agent generates code based on the schema of the dataframe and executes it. It doesn't always get it on the first try, but it is able to learn from the errors it sees to adjust and correct until it lands on an acceptable answer.\n",
    "\n",
    "Next, make a request that involves the agent importing new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86d21d-b52f-4797-a7bd-6102b33d49bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.invoke(\"What week of the year has the total highest sales overall?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fba518-fd15-4dc2-96db-c51cb84c6138",
   "metadata": {},
   "source": [
    "Now you probably don't want to include this natural language prompt directly into a production environment. Instead, we can ask Gemini to generate the PySparkSQL code for us that would create the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b41a6a-482c-4ce8-aa63-4e1c7d9de305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.invoke(\"Print the PySpark code that answers 'What week of the year has the total highest sales overall?' Include all necessary imports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc75dce-bfab-4652-850c-2242dc28f9a1",
   "metadata": {},
   "source": [
    "Like anything created by the still-maturing LLM technology, review generated code for accuracy."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "9c39b79e5d2e7072beb4bd59-next-2024",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "next-2024 on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-next-2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
