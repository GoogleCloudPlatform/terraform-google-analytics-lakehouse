{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "Spark in BigQuery"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Apache Spark in BigQuery Studio"
      ],
      "metadata": {
        "id": "svYTKvj-Z2by"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to use Apache Spark with your data in BigQuery."
      ],
      "metadata": {
        "id": "n0VEp4quZ7Ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will use the `gcp_lakehouse_ds.order_items` table, which is a managed [BigQuery table for Apache Iceberg](https://cloud.google.com/bigquery/docs/iceberg-tables)."
      ],
      "metadata": {
        "id": "MPXB_-2haWEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also install additional libraries via `pip` as desired."
      ],
      "metadata": {
        "id": "J28ZKhVfIu3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set your project id and project location."
      ],
      "metadata": {
        "id": "Ot69E4AlZXkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"\" # @param {type:\"string\"}\n",
        "location = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "z-3-7CHkFrTH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1743625521450,
          "user_tz": 240,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to a Spark Session configured to connect to BigQuery Metastore."
      ],
      "metadata": {
        "id": "orALJmCYyusK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.spark_connect import GoogleSparkSession\n",
        "from google.cloud.dataproc_v1 import Session\n",
        "\n",
        "session = Session()\n",
        "\n",
        "catalog = \"lakehouse_catalog\"\n",
        "\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}\"] = \"org.apache.iceberg.spark.SparkCatalog\"\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.catalog-impl\"] = \"org.apache.iceberg.gcp.bigquery.BigQueryMetastoreCatalog\"\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.gcp_project\"] = project_id\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.gcp_location\"] = location\n",
        "session.runtime_config.properties[f\"spark.sql.catalog.{catalog}.warehouse\"] = f\"gs://lakehouse-warehouse-{project_id}/warehouse\"\n",
        "\n",
        "## Create a Spark session with the new configuration:\n",
        "spark = GoogleSparkSession.builder.googleSessionConfig(session).getOrCreate()"
      ],
      "metadata": {
        "id": "wEFREPzx6lsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3f946c-9ef3-4f0d-d29c-fbfc79c28e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Spark session. It may take few minutes.\n",
            "Interactive Session Detail View:  https://console.cloud.google.com/dataproc/interactive/us-central1/sc-20250402-202523-mup834?project=data-cloud-demo7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "View the tables in your BigQuery dataset."
      ],
      "metadata": {
        "id": "mCWXnbLWAejM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(f\"USE {catalog};\")\n",
        "spark.sql(f\"USE {project_id};\")\n",
        "spark.sql(\"SHOW TABLES;\").show()"
      ],
      "metadata": {
        "id": "p2NN8wwF7YRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try asking Gemini how to query a specific table, such as a table in your generated `thelook_YOUR_PROJECT_ID`?"
      ],
      "metadata": {
        "id": "IKjlACN3A8va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how do I add 2+2?"
      ],
      "metadata": {
        "id": "dkb-QYOgLLRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRJz4pzcLfJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}