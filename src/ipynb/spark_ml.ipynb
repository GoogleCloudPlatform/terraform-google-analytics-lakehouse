{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d6c84304016"
   },
   "source": [
    "# SparkML with Dataproc Serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eee516156f1"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook tutorial demonstrates the execution of Apache SparkML jobs using Dataproc Serverless. This example machine learning pipeline ingests the [NYC TLC (Taxi and Limousine Commission) Trips](https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tlc-trips) dataset from your lakehouse and performs cleaning, feature engineering, model training, and model evaluation to calculate trip duration.\n",
    "\n",
    "The tutorial uses the following Google Cloud products:\n",
    "- `Dataproc`\n",
    "- `BigQuery`\n",
    "- `Vertex AI Training`\n",
    "- `BigLake`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2773979cd11d"
   },
   "source": [
    "## Tutorial\n",
    "\n",
    "### Set your project ID and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20366a83e3f1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the current active project and store it as a list of strings.\n",
    "PROJECT_ID = !gcloud config get-value project\n",
    "\n",
    "# Extract the project ID from the list.\n",
    "PROJECT_ID = PROJECT_ID[0] if PROJECT_ID else None\n",
    "\n",
    "# Retrieve the current location.\n",
    "LOCATION = !gcloud compute instances list --project={PROJECT_ID} --format='get(ZONE)'\n",
    "LOCATION = str(LOCATION).split(\"/\")[-1][:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73f5734153d4"
   },
   "source": [
    "### Get a Cloud Storage bucket URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06cb3320201b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prefix of the bucket created via Terraform.\n",
    "BUCKET_PREFIX = \"gcp-lakehouse-model\"\n",
    "\n",
    "# Retrieve the Cloud Storage bucket URI for storing the machine learning model.\n",
    "BUCKET_URI = !gcloud storage buckets list --format='value(name)' --filter='name:{BUCKET_PREFIX}*'\n",
    "\n",
    "# Extract the bucket URI from the list.\n",
    "BUCKET_URI = BUCKET_URI[0] if BUCKET_URI else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34dd442fd5af"
   },
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80ef02298a93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopandas import gpd\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "# A Spark Session is how you interact with Spark SQL to create Dataframes\n",
    "from pyspark.sql import SparkSession\n",
    "# PySpark functions\n",
    "from pyspark.sql.functions import col, floor, unix_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b6fb4d7c7f5"
   },
   "source": [
    "### Initialize the SparkSession\n",
    "\n",
    "Use the [spark-bigquery-connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) to read and write data between Apache Spark and BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ce77cd7c0d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "VER = \"0.34.0\"\n",
    "FILE_NAME = f\"spark-bigquery-with-dependencies_2.12-{VER}.jar\"\n",
    "connector = f\"gs://spark-lib/bigquery/{FILE_NAME}\"\n",
    "\n",
    "# Initialize the SparkSession.\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"spark-ml-taxi\")\n",
    "    .config(\"spark.jars\", connector)\n",
    "    .config(\"spark.logConf\", \"false\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a4080065c8b"
   },
   "source": [
    "### Fetch data\n",
    "\n",
    "Load the table `gcp_primary_staging.new_york_taxi_trips_tlc_yellow_trips_2022`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a5f19a732ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load NYC_taxi in Github Activity Public Dataset from BigQuery.\n",
    "taxi_df = (\n",
    "    spark.read.format(\"bigquery\")\n",
    "    .option(\n",
    "        \"table\",\n",
    "        f\"{PROJECT_ID}.gcp_primary_staging.new_york_taxi_trips_tlc_yellow_trips_2022\",\n",
    "    )\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# Sample parameter. Increase or decrease to experiment with different data sizes.\n",
    "FRACTION = 0.05\n",
    "\n",
    "# Sample data to minimize the runtime.\n",
    "taxi_df = taxi_df.sample(fraction=FRACTION, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26cef587d4de"
   },
   "source": [
    "### Perform Exploratory Data Analysis (EDA)\n",
    "\n",
    "Perform EDA to uncover more information about your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37d76ec684b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxi_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64d2006cab0f"
   },
   "source": [
    "Select and modify necessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0aa977e3d27",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose necessary columns.\n",
    "COLUMNS_TO_SELECT = [\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"trip_duration\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\",\n",
    "    \"mta_tax\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"imp_surcharge\",\n",
    "    \"airport_fee\",\n",
    "    \"total_amount\",\n",
    "    \"start_zone_id\",\n",
    "    \"end_zone_id\",\n",
    "]\n",
    "\n",
    "# Convert pickup_location_id and dropoff_location_id to integers for a later processing step:\n",
    "taxi_df = (\n",
    "  taxi_df.withColumn(\"start_zone_id\", col(\"pickup_location_id\").cast(\"int\"))  # Convert pickup_location_id to integer\n",
    "  .withColumn(\"end_zone_id\", col(\"dropoff_location_id\").cast(\"int\"))  # Convert dropoff_location_id to integer\n",
    ")\n",
    "\n",
    "# Convert datetime from string to Unix timestamp:\n",
    "taxi_df = (\n",
    "  taxi_df.withColumn(\"start_time\", unix_timestamp(col(\"pickup_datetime\")))  # Convert pickup_datetime to Unix timestamp\n",
    "  .withColumn(\"end_time\", unix_timestamp(col(\"dropoff_datetime\")))  # Convert dropoff_datetime to Unix timestamp\n",
    ")\n",
    "\n",
    "# Calculate trip_duration.\n",
    "taxi_df = taxi_df.withColumn(\"trip_duration\", col(\"end_time\") - col(\"start_time\"))\n",
    "\n",
    "# Select the specified columns:\n",
    "taxi_df = taxi_df.select(*COLUMNS_TO_SELECT)  # Selects columns based on the list in COLUMNS_TO_SELECT\n",
    "\n",
    "# Display summary statistics and preview the modified DataFrame.\n",
    "taxi_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "970761b1f949"
   },
   "source": [
    "Build a boxplot to further assess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame into a Pandas DataFrame.\n",
    "taxi_pd = taxi_df.toPandas()\n",
    "\n",
    "# Define columns to be converted to numerical type in Pandas and be visualized.\n",
    "PD_COLUMNS = [\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\",\n",
    "    \"mta_tax\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"imp_surcharge\",\n",
    "    \"airport_fee\",\n",
    "    \"total_amount\",\n",
    "]\n",
    "\n",
    "# Convert columns of \"object\" type to the float type.\n",
    "taxi_pd[PD_COLUMNS] = taxi_pd[PD_COLUMNS].astype(float)\n",
    "\n",
    "# Box plots and histograms for the specified columns.\n",
    "for column in taxi_pd.columns:\n",
    "    if column in PD_COLUMNS:\n",
    "        _, ax = plt.subplots(1, 2, figsize=(5, 2))\n",
    "        taxi_pd[column].plot(kind=\"box\", ax=ax[0])\n",
    "        taxi_pd[column].plot(kind=\"hist\", ax=ax[1])\n",
    "        plt.title(column)\n",
    "        plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these summary and boxplots, there are over 1 million trip histories for Yellow Taxi in 2022, which represents approximately 5% of the total trips. \n",
    "\n",
    "However, some trip histories have data anomalies. Trips exceeding 10,000 miles are beyond realistic expectations and will be excluded. Additionally, null and negative values in fare, tax, and tolls create inconsistencies and can distort analysis. Filter these values out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9196e32f245",
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxi_df = taxi_df.where(\n",
    "    (col(\"trip_distance\") < 10000)\n",
    "    & (col(\"fare_amount\") > 0)\n",
    "    & (col(\"extra\") >= 0)\n",
    "    & (col(\"mta_tax\") >= 0)\n",
    "    & (col(\"tip_amount\") >= 0)\n",
    "    & (col(\"tolls_amount\") >= 0)\n",
    "    & (col(\"imp_surcharge\") >= 0)\n",
    "    & (col(\"airport_fee\") >= 0)\n",
    "    & (col(\"total_amount\") > 0)\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a930952e7da"
   },
   "source": [
    "### Perform Feature Engineering\n",
    "\n",
    "While the Taxi dataset contains trips for all NYC boroughs, precise location information is categorized using `NYC Taxi zones`. Use the `bigquery-public-data.new_york_taxi_trips.taxi_zone_geom` public dataset to calculate longitude and latitude values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b58375ab96a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the GeoJSON format of NYC Taxi zones from the BigQuery public dataset.\n",
    "geo_df = (\n",
    "    spark.read.format(\"bigquery\")\n",
    "    .option(\"table\", \"bigquery-public-data.new_york_taxi_trips.taxi_zone_geom\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# Convert Spark DataFrame into Pandas DataFrame to integrate with the GeoPandas library.\n",
    "geo_pd = geo_df.toPandas()\n",
    "\n",
    "# Create a GeoDataFrame based on the central point of each taxi zone, separated by latitude and longitude.\n",
    "geo_pd[\"long\"] = gpd.GeoSeries.from_wkt(geo_pd[\"zone_geom\"]).centroid.x\n",
    "geo_pd[\"lat\"] = gpd.GeoSeries.from_wkt(geo_pd[\"zone_geom\"]).centroid.y\n",
    "\n",
    "# Drop unnecessary columns.\n",
    "geo_pd = geo_pd[[\"zone_id\", \"long\", \"lat\"]]\n",
    "\n",
    "# Convert back to a Spark DataFrame.\n",
    "geo_spark_df = spark.createDataFrame(geo_pd)\n",
    "\n",
    "# Join taxi_df with geographic position for each start_zone_id and end_zone_id.\n",
    "taxi_zone_df = (\n",
    "    taxi_df.join(geo_spark_df, taxi_df.start_zone_id == geo_spark_df.zone_id)\n",
    "    .withColumnRenamed(\"long\", \"start_long\")\n",
    "    .withColumnRenamed(\"lat\", \"start_lat\")\n",
    "    .drop(\"zone_id\")\n",
    "    .join(geo_spark_df, taxi_df.end_zone_id == geo_spark_df.zone_id)\n",
    "    .withColumnRenamed(\"long\", \"end_long\")\n",
    "    .withColumnRenamed(\"lat\", \"end_lat\")\n",
    "    .drop(\"zone_id\")\n",
    ")\n",
    "\n",
    "# Convert Spark DataFrame into a Pandas DataFrame.\n",
    "taxi_pd = taxi_df.toPandas()\n",
    "\n",
    "# Convert columns of \"object\" type to the float type.\n",
    "taxi_pd[\"trip_duration\"] = taxi_pd[\"trip_duration\"].astype(float)\n",
    "\n",
    "# Box plots and histograms for the specified columns.\n",
    "_, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "taxi_pd[\"trip_duration\"].plot(kind=\"box\", ax=ax[0])\n",
    "taxi_pd[\"trip_duration\"].plot(kind=\"hist\", ax=ax[1])\n",
    "plt.title(\"trip_duration\")\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6c42f747c421"
   },
   "source": [
    "`trip_duration` also has some extreme values. Remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4dda7df0ec8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter trips occurring between same taxi zones and exceeding where trip_duration is more than 28800 seconds (8 hours).\n",
    "taxi_df = taxi_zone_df.where(\n",
    "    (col(\"trip_duration\") < 28800) & (col(\"start_zone_id\") != col(\"end_zone_id\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f6dfc19b47e"
   },
   "source": [
    "Create the scatterplot to see the relationship between `trip_distance` and `trip_duration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edfff6a2abbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame into a Pandas DataFrame.\n",
    "taxi_pd = taxi_df.toPandas()\n",
    "\n",
    "# Convert \"trip_distance\" column of \"object\" type to the float type.\n",
    "taxi_pd[\"trip_distance\"] = taxi_pd[\"trip_distance\"].astype(float)\n",
    "\n",
    "# Filter the DataFrame to include data within reasonable ranges.\n",
    "taxi_pd_filtered = taxi_pd.query(\n",
    "    \"trip_distance > 0 and trip_distance < 20 \\\n",
    "    and trip_duration > 0 and trip_duration < 10000\"\n",
    ")\n",
    "\n",
    "# Scatter plot to visualize the relationship between trip_distance and trip_duration.\n",
    "sns.relplot(\n",
    "    data=taxi_pd_filtered,\n",
    "    x=\"trip_distance\",\n",
    "    y=\"trip_duration\",\n",
    "    kind=\"scatter\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9d42bffcebb"
   },
   "source": [
    "Takeaways here include:\n",
    "  * the data is right-skewed\n",
    "  * there is a positive correlation between `trip_distance` and `trip_duration`\n",
    "  * most trips are completed in under 3600 seconds (one hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e0ee0c6469c"
   },
   "source": [
    "### Feature Selection\n",
    "\n",
    "Use `VectorAssembler()` to consolidate feature columns into a vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c085bae96dec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of selected features for training the model.\n",
    "feature_cols = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "    \"start_long\",\n",
    "    \"start_lat\",\n",
    "    \"end_long\",\n",
    "    \"end_lat\",\n",
    "    \"total_amount\",\n",
    "    \"fare_amount\",\n",
    "    \"extra\",\n",
    "    \"mta_tax\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"imp_surcharge\",\n",
    "    \"airport_fee\",\n",
    "]\n",
    "\n",
    "# Create a VectorAssembler with specified input and output columns.\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Transform each column into vector form using the VectorAssembler.\n",
    "taxi_transformed_data = assembler.transform(taxi_df)\n",
    "\n",
    "# Randomly split the transformed data into training and test sets.\n",
    "(taxi_training_data, taxi_test_data) = taxi_transformed_data.randomSplit([0.95, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e68b4258d4d5"
   },
   "source": [
    "### Training the Model\n",
    "\n",
    "Use `GBTRegressor` model to train the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd2e2c8c4396",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define GBTRegressor model with specified input, output, and prediction columns.\n",
    "gbt = GBTRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"trip_duration\",\n",
    "    predictionCol=\"pred_trip_duration\",\n",
    ")\n",
    "\n",
    "# Define an evaluator for calculating the R2 score.\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol(), metricName=\"r2\"\n",
    ")\n",
    "\n",
    "# Define an evaluator for calculating the RMSE error.\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol(), metricName=\"rmse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3080a7ddabf9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a Gradient Boosted Trees (GBT) model on the Taxi dataset. This process may take several minutes.\n",
    "taxi_gbt_model = gbt.fit(taxi_training_data)\n",
    "\n",
    "# Get predictions for the Taxi dataset using the trained GBT model.\n",
    "taxi_gbt_predictions = taxi_gbt_model.transform(taxi_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4e4f60a8a3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the R2 score for the Taxi dataset predictions.\n",
    "taxi_gbt_accuracy_r2 = evaluator_r2.evaluate(taxi_gbt_predictions)\n",
    "print(f\"Taxi Test GBT R2 Accuracy = {taxi_gbt_accuracy_r2}\")\n",
    "\n",
    "# Evaluate the Root Mean Squared Error (RMSE) for the Taxi dataset predictions.\n",
    "taxi_gbt_accuracy_rmse = evaluator_rmse.evaluate(taxi_gbt_predictions)\n",
    "print(f\"Taxi Test GBT RMSE Accuracy = {taxi_gbt_accuracy_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d07452cd103"
   },
   "source": [
    "### View the result\n",
    "\n",
    "Expect an R2 score of approximately 83-87% and a Root Mean Square Error(RMSE) of 200-300. This sample does not include [Cross-validation (statistics)](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29) which can provide improved model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1b46847f395"
   },
   "source": [
    "### Save the model to Cloud Storage for future use\n",
    "\n",
    "To ensure the preservation and accessibility of the trained model, it can be saved to a Cloud Storage path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cc57f4362c4"
   },
   "outputs": [],
   "source": [
    "# Save the trained model to a Cloud Storage path\n",
    "taxi_gbt_model.write().overwrite().save(f\"gs://{BUCKET_URI}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Dataproc session template\n",
    "\n",
    "To delete the running Dataproc Serverless session, run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta dataproc session-templates delete sparkml-template --location='{LOCATION}' --quiet"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "spark_ml.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "9c39b79e5d2e7072beb4bd59-runtime-00002d16685d",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "test on Serverless Spark (Remote)",
   "language": "python",
   "name": "9c39b79e5d2e7072beb4bd59-runtime-00002d16685d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
